{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutomatedTamilSongGenerationUsingDeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1mj7wy3HNvjouVJdmjOJCeBsp_C1mvdr5",
      "authorship_tag": "ABX9TyPFNgP0W45sDRKYbaHlJcvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeereshElango/ai_powered_automated_tamil_song_lyrics_generator/blob/master/AutomatedTamilSongGenerationUsingDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4nyRTwRU2A0",
        "colab_type": "text"
      },
      "source": [
        "# AutomatedTamilSongGenerationUsingDeepLearning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2fCh_3H2pHs",
        "colab_type": "text"
      },
      "source": [
        "This notebook was built on top of Tensorflow's tutorial [Text generation with an RNN](https://www.tensorflow.org/tutorials/text/text_generation). The data utilized in this notebook can be find [here](https://cutt.ly/tt7krlz)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2-FVGqhfk9Q",
        "colab_type": "text"
      },
      "source": [
        "## Data Import & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvixjNKja50I",
        "colab_type": "code",
        "outputId": "228ba07e-aab2-4fda-d221-0877221cce80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR3qol8WblVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk7hJMfNeoQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/ColabDatasets/Public/tamil_song_lyrics/tamilsonglyrics.csv\", index_col=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rofA1nhe9Au",
        "colab_type": "code",
        "outputId": "b5bad73b-c8a5-4852-9bf8-d1e07b0c954f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df= df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lyricist</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>ஆ ஆ ஆ ஹஹஹ்ஹா ஆ ஆ\\r\\nஇன்பம் ...\\r\\nஇரவின் அமைதி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>கிளாசுல தூங்க மாட்டோம் வை மச்சி வை\\r\\nயூ டுபு ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vaali</td>\n",
              "      <td>பாட்டு தலைவன் பாடினால் பாட்டு தான்\\r\\nகூட்டம் ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arivumathi</td>\n",
              "      <td>ஆண் : ஆறடி சுவரு தான் ஆசையை தடுக்குமா\\r\\nகிளிய...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vairamuthu</td>\n",
              "      <td>ஆண் : குளிச்சா குத்தாலம்\\r\\nகும்பிட்டா பரமசிவம...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Lyricist                                             Lyrics\n",
              "0         NaN  ஆ ஆ ஆ ஹஹஹ்ஹா ஆ ஆ\\r\\nஇன்பம் ...\\r\\nஇரவின் அமைதி...\n",
              "1         NaN  கிளாசுல தூங்க மாட்டோம் வை மச்சி வை\\r\\nயூ டுபு ...\n",
              "2       Vaali  பாட்டு தலைவன் பாடினால் பாட்டு தான்\\r\\nகூட்டம் ...\n",
              "3  Arivumathi  ஆண் : ஆறடி சுவரு தான் ஆசையை தடுக்குமா\\r\\nகிளிய...\n",
              "4  Vairamuthu  ஆண் : குளிச்சா குத்தாலம்\\r\\nகும்பிட்டா பரமசிவம..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYkbNuWMGd4T",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8YYWwCSGcpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T06hgJ8OGldu",
        "colab_type": "code",
        "outputId": "87f2ce46-299e-4e58-b80c-7a155773707a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Combining all the lyrics to single string variable\n",
        "text = \" \".join([ song for song in df.Lyrics])\n",
        "print(\"Total songs combined : {}\".format(len(df.Lyrics)))\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total songs combined : 4142\n",
            "Length of text: 5266494 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjLJTOGqHZHy",
        "colab_type": "code",
        "outputId": "f4c18efb-2e37-4a1b-a4c2-9d75555bbbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ஆ ஆ ஆ ஹஹஹ்ஹா ஆ ஆ\r\n",
            "இன்பம் ...\r\n",
            "இரவின் அமைதியிலே\r\n",
            "தென்றல் இனிமையிலே\r\n",
            "\r\n",
            "\r\n",
            "ஆ .......\r\n",
            "இன்பம்\r\n",
            "வண்ண நிலவினிலே\r\n",
            "இன்பம் பேரின்பம்\r\n",
            "\r\n",
            "இசையே வீணையை மீட்டும்\r\n",
            "என் இசையே வீணையை மீட்டும்\r\n",
            "சொல்ல எழில் மிகும் வீணை இசைத்தே\r\n",
            "ஒரு அன்பு முத்தம் கொடுப்பேன்\r\n",
            "\r\n",
            "இன்பம் ,\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooR4OC5WHd6f",
        "colab_type": "code",
        "outputId": "78176830-a270-4b87-b2e1-797633c511d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGYP7ytQHkZz",
        "colab_type": "text"
      },
      "source": [
        "## Vectorize the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BFD50hdHgmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYzE7Qo2IC_A",
        "colab_type": "text"
      },
      "source": [
        "## Create training examples and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p15N7swaH3CM",
        "colab_type": "code",
        "outputId": "a920220c-894b-41dd-ae67-7148ab56620f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "# Sample\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ஆ\n",
            " \n",
            "ஆ\n",
            " \n",
            "ஆ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG1tIM0TIpYM",
        "colab_type": "code",
        "outputId": "ee4eb52b-cd64-48df-d3e4-437aa7c3dd42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'ஆ ஆ ஆ ஹஹஹ்ஹா ஆ ஆ\\r\\nஇன்பம் ...\\r\\nஇரவின் அமைதியிலே\\r\\nதென்றல் இனிமையிலே\\r\\n\\r\\n\\r\\nஆ .......\\r\\nஇன்பம்\\r\\nவண்ண நிலவின'\n",
            "'ிலே\\r\\nஇன்பம் பேரின்பம்\\r\\n\\r\\nஇசையே வீணையை மீட்டும்\\r\\nஎன் இசையே வீணையை மீட்டும்\\r\\nசொல்ல எழில் மிகும் வீணை இச'\n",
            "'ைத்தே\\r\\nஒரு அன்பு முத்தம் கொடுப்பேன்\\r\\n\\r\\nஇன்பம் ,\\r\\nஇக வாழ்வினிலே\\r\\nஎனதழியா பேரின்பம்\\r\\n\\r\\nஎன் எண்ணம் கைகூட'\n",
            "'ும்\\r\\nபொன்னான நாளிதுவே\\r\\nநீ என்னை பிரியாமல் இருப்பாயா கிளாசுல தூங்க மாட்டோம் வை மச்சி வை\\r\\nயூ டுபு பீ யூ'\n",
            "' ஸிக மாட்டோம் வை மச்சி வை\\r\\nஎஸ் எம் எஸ் பண்ண மாட்டோம் வை மச்சி வை\\r\\nபிகாஸ் உண்மை எல்லாம் பேச மாட்டோம்\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa3CNJs9Il71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C-9Fm2VJFCQ",
        "colab_type": "code",
        "outputId": "758b363b-07a7-4168-b2b4-a86132b6cc9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "for input_example, target_example in  dataset.take(5):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'ஆ ஆ ஆ ஹஹஹ்ஹா ஆ ஆ\\r\\nஇன்பம் ...\\r\\nஇரவின் அமைதியிலே\\r\\nதென்றல் இனிமையிலே\\r\\n\\r\\n\\r\\nஆ .......\\r\\nஇன்பம்\\r\\nவண்ண நிலவி'\n",
            "Target data: ' ஆ ஆ ஹஹஹ்ஹா ஆ ஆ\\r\\nஇன்பம் ...\\r\\nஇரவின் அமைதியிலே\\r\\nதென்றல் இனிமையிலே\\r\\n\\r\\n\\r\\nஆ .......\\r\\nஇன்பம்\\r\\nவண்ண நிலவின'\n",
            "Input data:  'ிலே\\r\\nஇன்பம் பேரின்பம்\\r\\n\\r\\nஇசையே வீணையை மீட்டும்\\r\\nஎன் இசையே வீணையை மீட்டும்\\r\\nசொல்ல எழில் மிகும் வீணை இ'\n",
            "Target data: 'லே\\r\\nஇன்பம் பேரின்பம்\\r\\n\\r\\nஇசையே வீணையை மீட்டும்\\r\\nஎன் இசையே வீணையை மீட்டும்\\r\\nசொல்ல எழில் மிகும் வீணை இச'\n",
            "Input data:  'ைத்தே\\r\\nஒரு அன்பு முத்தம் கொடுப்பேன்\\r\\n\\r\\nஇன்பம் ,\\r\\nஇக வாழ்வினிலே\\r\\nஎனதழியா பேரின்பம்\\r\\n\\r\\nஎன் எண்ணம் கைகூ'\n",
            "Target data: 'த்தே\\r\\nஒரு அன்பு முத்தம் கொடுப்பேன்\\r\\n\\r\\nஇன்பம் ,\\r\\nஇக வாழ்வினிலே\\r\\nஎனதழியா பேரின்பம்\\r\\n\\r\\nஎன் எண்ணம் கைகூட'\n",
            "Input data:  'ும்\\r\\nபொன்னான நாளிதுவே\\r\\nநீ என்னை பிரியாமல் இருப்பாயா கிளாசுல தூங்க மாட்டோம் வை மச்சி வை\\r\\nயூ டுபு பீ ய'\n",
            "Target data: 'ம்\\r\\nபொன்னான நாளிதுவே\\r\\nநீ என்னை பிரியாமல் இருப்பாயா கிளாசுல தூங்க மாட்டோம் வை மச்சி வை\\r\\nயூ டுபு பீ யூ'\n",
            "Input data:  ' ஸிக மாட்டோம் வை மச்சி வை\\r\\nஎஸ் எம் எஸ் பண்ண மாட்டோம் வை மச்சி வை\\r\\nபிகாஸ் உண்மை எல்லாம் பேச மாட்டோம்\\r'\n",
            "Target data: 'ஸிக மாட்டோம் வை மச்சி வை\\r\\nஎஸ் எம் எஸ் பண்ண மாட்டோம் வை மச்சி வை\\r\\nபிகாஸ் உண்மை எல்லாம் பேச மாட்டோம்\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgdMI_0dJTal",
        "colab_type": "code",
        "outputId": "a8282f70-d9f8-434f-d844-7dfb9f4aaf68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 2 (' ')\n",
            "  expected output: 141 ('ஸ')\n",
            "Step    1\n",
            "  input: 141 ('ஸ')\n",
            "  expected output: 144 ('ி')\n",
            "Step    2\n",
            "  input: 144 ('ி')\n",
            "  expected output: 120 ('க')\n",
            "Step    3\n",
            "  input: 120 ('க')\n",
            "  expected output: 2 (' ')\n",
            "Step    4\n",
            "  input: 2 (' ')\n",
            "  expected output: 131 ('ம')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnDp1Wc7JcV6",
        "colab_type": "code",
        "outputId": "32ac9341-1af7-4249-ba1a-818b4898f0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_OVCCqMJpyE",
        "colab_type": "text"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fJxIc5cJmNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7gsM2UbJroM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaqJwEh1Jx1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqlWjJZPJ0iJ",
        "colab_type": "code",
        "outputId": "5e638121-5c48-4d41-ddb5-9d96e37fe01e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 172) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-b8kxklyxfj",
        "colab_type": "code",
        "outputId": "c618244d-84ed-44b1-d7fc-027583de3ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_example_batch.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxe4YcA2J5U7",
        "colab_type": "code",
        "outputId": "63b3a7b6-2a7f-484b-a6bb-7a70bcd73453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           44032     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (64, None, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 172)           176300    \n",
            "=================================================================\n",
            "Total params: 13,860,012\n",
            "Trainable params: 13,860,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEeSUQztJ7V1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weA-ZIwKJ9qf",
        "colab_type": "code",
        "outputId": "2b3b379b-4889-40e9-df88-0db30561de5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'een light போல் ஓகே சொல்லும் marriage வாழ்க்கை தானே\\r\\nநடுவில் ஒரு yellow line தான் novelty\\r\\nDJ DJ டிஸ்'\n",
            "\n",
            "Next Char Predictions: \n",
            " \"ஞற—ஜ’lSÕகx@0யௌ‘;ºணx.க▪\\\\ஈ‘$ணDZCRr}`ஃ)‐mஅ௨T`Õஞ– ug<௨3'lMாb}ீºD்N`UனuÕஓb4pHvq\\xad`\\u200dவM=லNj*OZ▪ा@?gwT¤<▪’ஞ!e\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbLkUNbcKB0U",
        "colab_type": "code",
        "outputId": "ccb67062-8c16-4d1f-adf9-ead98163b186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 172)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       5.147275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIjlrTJKGIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PLC0HCWKHu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='loss'\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXWw5qXLKKI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiuNSPN8KMQI",
        "colab_type": "code",
        "outputId": "0b35bd8f-c93d-4a11-ea9d-2cbb898c8c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "814/814 [==============================] - 96s 118ms/step - loss: 1.9695\n",
            "Epoch 2/30\n",
            "814/814 [==============================] - 96s 117ms/step - loss: 1.5213\n",
            "Epoch 3/30\n",
            "814/814 [==============================] - 96s 117ms/step - loss: 1.4123\n",
            "Epoch 4/30\n",
            "814/814 [==============================] - 96s 117ms/step - loss: 1.3349\n",
            "Epoch 5/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 1.2687\n",
            "Epoch 6/30\n",
            "814/814 [==============================] - 96s 118ms/step - loss: 1.2092\n",
            "Epoch 7/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 1.1545\n",
            "Epoch 8/30\n",
            "814/814 [==============================] - 96s 117ms/step - loss: 1.1051\n",
            "Epoch 9/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 1.0600\n",
            "Epoch 10/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 1.0202\n",
            "Epoch 11/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.9838\n",
            "Epoch 12/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.9516\n",
            "Epoch 13/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.9230\n",
            "Epoch 14/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.8977\n",
            "Epoch 15/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.8757\n",
            "Epoch 16/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.8561\n",
            "Epoch 17/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.8394\n",
            "Epoch 18/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.8248\n",
            "Epoch 19/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.8111\n",
            "Epoch 20/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.8004\n",
            "Epoch 21/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.7903\n",
            "Epoch 22/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.7808\n",
            "Epoch 23/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.7739\n",
            "Epoch 24/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.7675\n",
            "Epoch 25/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.7613\n",
            "Epoch 26/30\n",
            "814/814 [==============================] - 95s 116ms/step - loss: 0.7560\n",
            "Epoch 27/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.7519\n",
            "Epoch 28/30\n",
            "814/814 [==============================] - 95s 117ms/step - loss: 0.7490\n",
            "Epoch 29/30\n",
            "814/814 [==============================] - 96s 118ms/step - loss: 0.7480\n",
            "Epoch 30/30\n",
            "814/814 [==============================] - 96s 118ms/step - loss: 0.7459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1zHyUy79B38",
        "colab_type": "text"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjrc4Ii8KygK",
        "colab_type": "code",
        "outputId": "184bce54-fb9f-4f92-a6d3-d4b92510445c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install tensorflowjs"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/30/f0219d23258fe5ba8cfc52b27d94d7ad6316deb4318db782db3958c9e18f/tensorflowjs-1.7.2-py3-none-any.whl (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hCollecting tensorflow-hub==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 35.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 39.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.18.2)\n",
            "Collecting PyInquirer==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/4c/434b7c454010a284b49d6f1d446fe8dc5960415613d8c0225b9e2efb6724/PyInquirer-1.0.3.tar.gz\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Collecting tensorflow-cpu==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/a9/d8e5118b4cc096633c04677809f0000519c43043b01311da02678349acf4/tensorflow_cpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (104.6MB)\n",
            "\u001b[K     |████████████████████████████████| 104.6MB 30kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0->tensorflowjs) (3.10.0)\n",
            "Collecting prompt_toolkit==1.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/3d/b25d35a9f0d381dd1c02d8e04b37c353caaaff4bc32150328eeebe4931f5/prompt_toolkit-1.0.14-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 56.0MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/68/106af3ae51daf807e9cdcba6a90e518954eb8b70341cee52995540a53ead/Pygments-2.6.1-py3-none-any.whl (914kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 61.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2016.11.21 in /usr/local/lib/python3.6/dist-packages (from PyInquirer==1.0.3->tensorflowjs) (2019.12.20)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (3.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 63.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (1.28.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu==2.1.0->tensorflowjs) (1.0.8)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 60.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.7.0->tensorflowjs) (46.1.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt_toolkit==1.0.14->PyInquirer==1.0.3->tensorflowjs) (0.1.9)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (2.21.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-cpu==2.1.0->tensorflowjs) (3.1.0)\n",
            "Building wheels for collected packages: PyInquirer, gast\n",
            "  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyInquirer: filename=PyInquirer-1.0.3-cp36-none-any.whl size=32851 sha256=7dedfe8548bdfbad54c931d6e34d96f8502b3c97f55f775b85d2f172c704ccd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/6c/b1/3e4b0e8daf42a92883c7641c0ea8ffb62e0490ebed2faa55ad\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=59451d422d617da06f6c089b0619313b47b531aa3aa28edac8048957ba396875\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built PyInquirer gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-hub, prompt-toolkit, Pygments, PyInquirer, tensorflow-estimator, gast, tensorboard, tensorflow-cpu, tensorflowjs\n",
            "  Found existing installation: tensorflow-hub 0.8.0\n",
            "    Uninstalling tensorflow-hub-0.8.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.8.0\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "Successfully installed PyInquirer-1.0.3 Pygments-2.6.1 gast-0.2.2 prompt-toolkit-1.0.14 tensorboard-2.1.1 tensorflow-cpu-2.1.0 tensorflow-estimator-2.1.0 tensorflow-hub-0.7.0 tensorflowjs-1.7.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "prompt_toolkit",
                  "pygments",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v30scc6sJJQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflowjs as tfjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "31b655ad-13e1-4a55-f4ce-035c22ebe8e9",
        "id": "41nhkIGqvnw9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tfjs.converters.save_keras_model(model, \"./drive/My Drive/ColabDatasets/trained_models/fullsongs_model\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/keras_h5_conversion.py:122: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  return h5py.File(h5file)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbWUGupPMtZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUDeDYTUNt8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx_str = json.dumps(char2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBT0P30pN1dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"./drive/My Drive/ColabDatasets/trained_models/fullsongs_model/char_idx_converter.js\",\"w\") as f:\n",
        "  f.write(\"var char2idx =\"+ str(char2idx)+\"; \\n var idx2char = \"+str(idx2char.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afYvSlJ686wL",
        "colab_type": "text"
      },
      "source": [
        "## Checking Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDxjP197KOQf",
        "colab_type": "code",
        "outputId": "cbbcff93-8a82-40fc-8da8-db8789fceeb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGUfAwucCHMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjCIXI_PCKmB",
        "colab_type": "code",
        "outputId": "b8242e8e-802f-4473-a5d5-605845e93d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            44032     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 172)            176300    \n",
            "=================================================================\n",
            "Total params: 13,860,012\n",
            "Trainable params: 13,860,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkTsAYCnCMcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string, temperature=1.0):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 500\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = temperature\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature \n",
        "      cat_dist_predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([cat_dist_predicted_id], 0)\n",
        "      #print(input_eval)\n",
        "      text_generated.append(idx2char[cat_dist_predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru7LA9mWCRMC",
        "colab_type": "code",
        "outputId": "a8aafbad-e5cb-448f-99c8-cd1360cba899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(generate_text(model, start_string=u\"அ\", temperature=0.8))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "அடங்குமா\r\n",
            "நீயும் வந்தா கூட\r\n",
            "பூ பூக்கவே மறு புறாவே....(துள்ளி)\r\n",
            "தாலி கட்ட சேர்ந்த தான்\r\n",
            "என்ன கேட்டு கேட்க நீ பார்த்தா\r\n",
            "அவக்கை எங்க கூர கொண்டாட்டம்தான்\r\n",
            "ஒரு சின்னச் சின்ன அவனைக் கேளு\r\n",
            "\r\n",
            "ஆண்: சுத்தி சுத்தி வந்தீக கோபக் குருவி மலருது Rad\r\n",
            "வா வா வா\r\n",
            "\r\n",
            "மண்ணில் இந்தக் குயில் நீயும் வந்தால் ஆடும் இளம் பூங்கொடி!\r\n",
            "\r\n",
            "பறவை பூத்த தோட்டத்தில் ம் பாரு அது\r\n",
            "தின்னா தின்னக் தினத்தின்\r\n",
            "தின்னா தின்னக்கி திக்கெட் தின்னாரபரு\r\n",
            "எல்லாம் பொய்யும் புரியலையே\r\n",
            "\r\n",
            "பாட்டு ஒன்னு கட்டி வச்சேனே வா வா வா\r\n",
            "கட்டிக்கிட நான் தொட்டதெல்ல\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LZgbHaxdpuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}